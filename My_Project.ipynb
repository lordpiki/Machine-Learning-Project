{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxEltSUHS4bN",
        "outputId": "92e542d4-1efc-4715-d34b-483859f30694"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import time\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "import sys\n",
        "# sys.path.append('/content/gdrive/My Drive')\n",
        "# import unit10.utils as u10\n",
        "\n",
        "import os\n",
        "# from sklearn.datasets import fetch_openml\n",
        "# from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wMzKe0DWS-LH"
      },
      "outputs": [],
      "source": [
        "class ITrainable():\n",
        "  pass\n",
        "  def forward_propagation(self, X):\n",
        "    raise NotImplementedError(\"Not Implemented\")\n",
        "\n",
        "  def backward_propagation(self, dY_hat):\n",
        "    raise NotImplementedError(\"Not Implemented\")\n",
        "\n",
        "  def update_parameters(self):\n",
        "    raise NotImplementedError(\"Not Implemented\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "F9kcc1xXS-UF"
      },
      "outputs": [],
      "source": [
        "class DLLinearLayer(ITrainable):\n",
        "  def __init__(self,name,num_units,input_size, alpha,optimize = None):\n",
        "    self.name = name\n",
        "    self.alpha = alpha\n",
        "    self.optimization = optimize\n",
        "    self.input_size = input_size\n",
        "    self.num_units = num_units\n",
        "    self.b = np.zeros((num_units,1),dtype = float)\n",
        "    self.W_Xaviar_initialization()\n",
        "    if(self.optimization == 'adaptive'):\n",
        "      self.adaptive_cont = 1.1\n",
        "      self.adaptive_switch = 0.5\n",
        "      self.adaptive_W = np.full(self.W.shape,alpha,dtype = float)\n",
        "      self.adaptive_b = np.full(self.b.shape,alpha,dtype = float)\n",
        "\n",
        "  def set_W(self,W):\n",
        "    self.W = np.copy(W)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def normal_initialization(shape,factor=0.01):\n",
        "    return np.random.randn(*shape)*factor\n",
        "\n",
        "  def W_He_initialization(self):\n",
        "    self.W = DLLinearLayer.normal_initialization((self.num_units,self.input_size,),np.sqrt(2/self.input_size))\n",
        "\n",
        "  def W_Xaviar_initialization(self):\n",
        "    self.W = DLLinearLayer.normal_initialization((self.num_units,self.input_size),1/np.sqrt(self.input_size))\n",
        "\n",
        "\n",
        "  def save_parameters(self,file_path):\n",
        "    file_name = file_path+\"/\"+self.name+\".h5\"\n",
        "    with h5py.File(file_name, 'w') as hf:\n",
        "      hf.create_dataset(\"W\", data=self.W)\n",
        "      hf.create_dataset(\"b\", data=self.b)\n",
        "\n",
        "  def restore_parameters(self,file_path):\n",
        "    file_name = file_path+\"/\"+self.name+\".h5\"\n",
        "    with h5py.File(file_name, 'r') as hf:\n",
        "      self.W = hf['W'][:]\n",
        "      self.b = hf['b'][:]\n",
        "\n",
        "  def forward_propagation(self, prev_A):\n",
        "    self.prev_A = np.copy(prev_A)\n",
        "    Z = self.W @ prev_A + self.b\n",
        "    return Z\n",
        "\n",
        "  def get_W(self):\n",
        "    return self.W\n",
        "\n",
        "  def backward_propagation(self, dZ):\n",
        "    self.db = np.sum(dZ, keepdims=True, axis=1)\n",
        "    self.dW = dZ@self.prev_A.T\n",
        "    return self.W.T@dZ\n",
        "\n",
        "\n",
        "  def update_parameters(self):\n",
        "    if self.optimization == 'adaptive':\n",
        "      self.adaptive_W *= np.where(self.adaptive_W * self.dW > 0, self.adaptive_cont, -self.adaptive_switch)\n",
        "      self.W -= self.adaptive_W\n",
        "      self.adaptive_b *= np.where(self.adaptive_b * self.db > 0, self.adaptive_cont, -self.adaptive_switch)\n",
        "      self.b -= self.adaptive_b\n",
        "    else:\n",
        "      self.W -= self.alpha * self.dW\n",
        "      self.b -= self.alpha * self.db\n",
        "\n",
        "  def __str__(self):\n",
        "    s = self.name + \" Function:\\n\"\n",
        "    s += \"\\tlearning_rate (alpha): \" + str(self.alpha) + \"\\n\"\n",
        "    if self.optimization != None:\n",
        "      s += \"\\toptimization: \" + str(self.optimization) + \"\\n\"\n",
        "    if self.optimization == \"adaptive\":\n",
        "      s += \"\\t\\tadaptive parameters:\\n\"\n",
        "      s += \"\\t\\t\\tcont: \" + str(self.adaptive_cont)+\"\\n\"\n",
        "      s += \"\\t\\t\\tswitch: \" + str(self.adaptive_switch)+\"\\n\"\n",
        "    # parameters\n",
        "    s += \"\\tParameters: W shape = \"+str(self.W.shape)+\", b = \"+str(self.b.shape)+\"\\n\"\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KlP43K7MS-ZV"
      },
      "outputs": [],
      "source": [
        "class DLNetwork(ITrainable):\n",
        "  def __init__(self,name):\n",
        "    self.name = name\n",
        "    self.layers = []\n",
        "\n",
        "  def add_layer(self,iTrainable):\n",
        "    self.layers.append(iTrainable)\n",
        "\n",
        "  def forward_propagation(self, X):\n",
        "    self.__X = X\n",
        "    kelet = X\n",
        "    for layer in self.layers:\n",
        "      kelet = layer.forward_propagation(kelet)\n",
        "    return kelet\n",
        "\n",
        "  def backward_propagation(self, dY_hat):\n",
        "    kelet= dY_hat\n",
        "    for layer in self.layers[::-1]:\n",
        "      kelet = layer.backward_propagation(kelet)\n",
        "    return kelet\n",
        "\n",
        "  def save_parameters(self,dir_path):\n",
        "    path = dir_path+\"/\"+self.name\n",
        "    if os.path.exists(path)== False:\n",
        "      os.mkdir(path)\n",
        "      for layer in self.layers:\n",
        "        layer.save_parameters(path)\n",
        "\n",
        "  def restore_parameters(self, dir_path):\n",
        "    path = dir_path+\"/\"+self.name\n",
        "    for layer in self.layers:\n",
        "      layer.restore_parameters(path)\n",
        "\n",
        "  def update_parameters(self):\n",
        "    for layer in self.layers:\n",
        "      layer.update_parameters()\n",
        "\n",
        "  def __str__(self):\n",
        "    s = self.name+'\\n'\n",
        "    for layer in self.layers:\n",
        "      s+=layer.__str__()\n",
        "    return s\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mWKYn2ayS-bk"
      },
      "outputs": [],
      "source": [
        "class DLModel:\n",
        "  def __init__(self,name,iTrainable,loss):\n",
        "    self.name = name\n",
        "    self.iTrainable = iTrainable\n",
        "    self.loss = loss\n",
        "    if(loss == 'categorical_cross_entropy'):\n",
        "      self.loss_forward = self.categorical_cross_entropy\n",
        "      self.loss_backward = self.dCategorical_cross_entropy\n",
        "    if(loss ==\"square_dist\"):\n",
        "      self.loss_forward = self.square_dist\n",
        "      self.loss_backward = self.dSquare_dist\n",
        "    if(loss == \"cross_entropy\"):\n",
        "      self.loss_forward = self.cross_entropy\n",
        "      self.loss_backward = self.dCross_entropy\n",
        "\n",
        "  @staticmethod\n",
        "  def to_one_hot(num_categories, Y):\n",
        "    m = Y.shape[0]\n",
        "    Y = Y.reshape(1, m)\n",
        "    Y_new = np.eye(num_categories)[Y.astype('int32')]\n",
        "    Y_new = Y_new.T.reshape(num_categories, m)\n",
        "    return Y_new\n",
        "\n",
        "  def __str__(self):\n",
        "    s = self.name + \"\\n\"\n",
        "    s += \"\\tLoss function: \" + self.loss + \"\\n\"\n",
        "    s += \"\\t\"+str(self.iTrainable) + \"\\n\"\n",
        "    return s\n",
        "\n",
        "  def categorical_cross_entropy(self, Y_hat, Y):\n",
        "    eps = 1e-10\n",
        "    Y_hat = np.where(Y_hat==0,eps,Y_hat)\n",
        "    Y_hat = np.where(Y_hat == 1, 1-eps,Y_hat)\n",
        "    errors = np.zeros(Y.shape[1])\n",
        "    errors = -np.sum(Y*np.log(Y_hat),axis = 0)\n",
        "    return errors\n",
        "\n",
        "  def dCategorical_cross_entropy(self,Y_hat,Y):\n",
        "    return (-Y+Y_hat)/Y.shape[1]\n",
        "\n",
        "  def cross_entropy(self,Y_hat,Y):\n",
        "    eps = 1e-10\n",
        "    Y_hat = np.where(Y_hat==0,eps,Y_hat)\n",
        "    Y_hat = np.where(Y_hat == 1, 1-eps,Y_hat)\n",
        "    return -(Y*np.log(Y_hat)+(np.full(Y.shape,1,dtype=float)-Y)*np.log(np.full(Y.shape,1,dtype=float)-Y_hat))\n",
        "\n",
        "  def dCross_entropy(self,Y_hat,Y):\n",
        "    eps = 1e-10\n",
        "    Y_hat = np.where(Y_hat==0,eps,Y_hat)\n",
        "    Y_hat = np.where(Y_hat == 1, 1-eps,Y_hat)\n",
        "    return (1/Y.shape[1])*(-Y*Y_hat**(-1)+(np.full(Y.shape,1,dtype=float)-Y)*(np.full(Y.shape,1,dtype=float)-Y_hat)**-1)\n",
        "\n",
        "\n",
        "  def square_dist(self, Y_hat, Y):\n",
        "    errors = (Y_hat - Y)**2\n",
        "    return errors\n",
        "\n",
        "  def dSquare_dist(self, Y_hat, Y):\n",
        "    m = Y.shape[1]\n",
        "    dY_hat = 2*(Y_hat - Y)/m\n",
        "    return dY_hat\n",
        "\n",
        "  def compute_cost(self, Y_hat, Y):\n",
        "    m = Y.shape[1]\n",
        "    errors = self.loss_forward(Y_hat, Y)\n",
        "    J = np.sum(errors)\n",
        "    return J/m\n",
        "\n",
        "  def confusion_matrix(self, X, Y):\n",
        "    prediction = self.forward_propagation(X)\n",
        "    prediction_index = np.argmax(prediction, axis=0)\n",
        "    Y_index = np.argmax(Y, axis=0)\n",
        "    right = np.sum(prediction_index == Y_index)\n",
        "    print(\"accuracy: \",str(right/len(Y[0])))\n",
        "    print(confusion_matrix(prediction_index, Y_index))\n",
        "\n",
        "  def backward_propagation(self,Y_hat,Y):\n",
        "    dY_hat = self.loss_backward(Y_hat,Y)\n",
        "    self.iTrainable.backward_propagation(dY_hat)\n",
        "\n",
        "  def forward_propagation(self,X):\n",
        "    return self.iTrainable.forward_propagation(X)\n",
        "\n",
        "  def train(self,X,Y,num_iterations):\n",
        "    print_ind = max(num_iterations // 100, 1)\n",
        "    costs = []\n",
        "    for i in range(num_iterations):\n",
        "      Y_hat = self.iTrainable.forward_propagation(X)\n",
        "      self.backward_propagation(Y_hat,Y)\n",
        "      self.iTrainable.update_parameters()\n",
        "\n",
        "      if i > 0 and i % print_ind == 0:\n",
        "        J = self.compute_cost(Y_hat, Y)\n",
        "        print(\"cost:\",J,i/print_ind,\"%\")\n",
        "        costs.append(J)\n",
        "    costs.append(self.compute_cost(Y_hat, Y))\n",
        "    return costs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YnfO02h8TO6Z"
      },
      "outputs": [],
      "source": [
        "class DLNeuronsLayer(DLNetwork):\n",
        "  def __init__(self,name,num_units,input_size,activation,alpha,optimization=None):\n",
        "    self.name = name\n",
        "    self.linear = DLLinearLayer(\"Linear\",num_units,input_size,alpha,optimization)\n",
        "    self.activation = DLActivation(activation)\n",
        "    super().__init__(name)\n",
        "    super().add_layer(self.linear)\n",
        "    super().add_layer(self.activation)\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.linear.__str__()+self.activation.__str__()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8BNYfvPuTRim"
      },
      "outputs": [],
      "source": [
        "class DLActivation(ITrainable):\n",
        "  def __init__(self,activation):\n",
        "    self.name = activation\n",
        "    if activation == \"tanh\":\n",
        "      self.forward_propagation =self.tanh\n",
        "      self.backward_propagation =self.tanh_dZ\n",
        "    elif activation == \"relu\":\n",
        "      self.forward_propagation =self.relu\n",
        "      self.backward_propagation =self.relu_dZ\n",
        "    elif activation == \"leaky_relu\":\n",
        "      self.leaky_relu_d = 0.01\n",
        "      self.forward_propagation =self.leaky_relu\n",
        "      self.backward_propagation = self.leaky_relu_dZ\n",
        "    elif activation == \"sigmoid\":\n",
        "      self.forward_propagation = self.sigmoid\n",
        "      self.backward_propagation =self.sigmoid_dZ\n",
        "    elif activation =='softmax':\n",
        "      self.forward_propagation = self.softmax\n",
        "      self.backward_propagation =self.softmax_dZ\n",
        "    else:\n",
        "      raise Exception(\"Undifiend activation\")\n",
        "\n",
        "  def sigmoid(self, Z):\n",
        "    self.res = 1/(1+np.exp(-1*Z))\n",
        "    return self.res\n",
        "\n",
        "  def sigmoid_dZ(self, dA):\n",
        "    self.dZ = dA*self.res*(np.full(self.res.shape,1,dtype=float)-self.res)\n",
        "    return self.dZ\n",
        "\n",
        "  def softmax(self,Z):\n",
        "    return np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
        "\n",
        "  def softmax_dZ(self,dZ):\n",
        "    return dZ\n",
        "\n",
        "  def tanh(self, Z):\n",
        "    self.res = np.tanh(Z)\n",
        "    return self.res\n",
        "\n",
        "  def tanh_dZ(self,dA):\n",
        "    return dA*(1-self.res**2)\n",
        "\n",
        "  def relu(self, Z):\n",
        "    self.Z = Z\n",
        "    return np.maximum(0,Z)\n",
        "\n",
        "  def relu_dZ(self,dA):\n",
        "    return np.where(self.Z <= 0, 0, 1)*dA\n",
        "\n",
        "  def leaky_relu(self,Z):\n",
        "    self.Z = Z\n",
        "    return np.where(self.Z <= 0, self.leaky_relu_d*self.Z, self.Z)\n",
        "\n",
        "  def leaky_relu_dZ(self,dA):\n",
        "    return np.where(self.Z <= 0, self.leaky_relu_d, 1)*dA\n",
        "\n",
        "\n",
        "  def update_parameters(self):\n",
        "     pass\n",
        "\n",
        "  def save_parameters(self,path):\n",
        "    pass\n",
        "  def restore_parameters(self,path):\n",
        "    pass\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Activation: \"+self.name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJfXH5o3x-6x",
        "outputId": "85bd0f04-928a-432a-be34-53c4b2318d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check: True , diff: 1.5040645465357203e-09\n",
            "check: False , diff: 0.00017993850937502074\n"
          ]
        }
      ],
      "source": [
        "class testGrad():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  @staticmethod\n",
        "  def check_grad(f,x,f_grad,epsilon = 1e-4,delta = 1e-7):\n",
        "    aprox = (f(x+delta)-f(x-delta))/(2*delta)\n",
        "    grad = f_grad(x)\n",
        "    print(aprox,grad)\n",
        "    diff = abs(aprox-grad)/(abs(aprox)+abs(grad))\n",
        "    return (diff<epsilon,diff)\n",
        "\n",
        "  @staticmethod\n",
        "  def check_n_grad(f , parms_vec, grad_vec, epsilon=1e-4 , delta=1e-7):\n",
        "    n = len(parms_vec)\n",
        "    approx = np.zeros(parms_vec.shape)\n",
        "    for i in range(n):\n",
        "      pars_plus = np.copy(parms_vec)\n",
        "      pars_plus[i]+=delta\n",
        "      pars_min = np.copy(parms_vec)\n",
        "      pars_min[i]-=delta\n",
        "      approx[i] = (-f(pars_min)+f(pars_plus))/(2*delta)\n",
        "    above = np.linalg.norm(approx-grad_vec)\n",
        "    bottom = np.linalg.norm(approx)+np.linalg.norm(grad_vec)\n",
        "    diff = above/bottom\n",
        "    return (diff<epsilon,diff)\n",
        "\n",
        "\n",
        "def g(parms):\n",
        "    a,b = parms[0], parms[1]\n",
        "    return 2*a**2+4*a*b-3*b**2\n",
        "\n",
        "def dg_da(a,b):\n",
        "    return 4*a+4*b\n",
        "def dg_db(a,b):\n",
        "    return 4*a-6*b\n",
        "def dg_db_wrong(a,b):\n",
        "    return 4*a-6*b+0.01\n",
        "a,b = 5.0,1.0\n",
        "check, diff = testGrad.check_n_grad(g, np.array([a,b]), np.array([dg_da(a,b),dg_db(a,b)]))\n",
        "print(\"check:\",str(check), \", diff:\", str(diff))\n",
        "check, diff = testGrad.check_n_grad(g, np.array([a,b]), np.array([dg_da(a,b),dg_db_wrong(a,b)]))\n",
        "print(\"check:\",str(check), \", diff:\", str(diff))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "mO2Q_UJ9rvcN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # mnist = fetch_openml('mnist_784')\n",
        "# # X, Y = mnist[\"data\"], mnist[\"target\"]\n",
        "# # X = np.array(X) # just in case…\n",
        "# # Y = np.array(Y) # just in case…\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WAFqx6lcb741"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Install the Kaggle package\n",
        "# !pip install kaggle\n",
        "\n",
        "# # Upload your kaggle.json file\n",
        "# # from google.colab import files\n",
        "# # files.upload()\n",
        "\n",
        "# # Move kaggle.json to the correct directory and set permissions\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGNnjYdIvsuz",
        "outputId": "8745784b-172a-4746-ce5f-44e00b2566ce"
      },
      "outputs": [],
      "source": [
        "# # Download the handwritten digits dataset\n",
        "# !kaggle datasets download -d jcprogjava/handwritten-digits-dataset-not-in-mnist\n",
        "\n",
        "# # Unzip the downloaded files\n",
        "# !unzip handwritten-digits-dataset-not-in-mnist.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "idjAmS9KxbdL"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "\n",
        "# import os\n",
        "# import random\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def array_to_image(array):\n",
        "#     # Check if the array size is correct for a 28x28 image\n",
        "#     if array.size != 28 * 28:\n",
        "#         raise ValueError(\"The input array must have 784 elements (28x28).\")\n",
        "\n",
        "#     # Reshape the array back into a 28x28 image\n",
        "#     image = array.reshape(28, 28)\n",
        "\n",
        "#     # Display the image\n",
        "#     plt.imshow(image, cmap='gray')\n",
        "#     plt.axis('off')  # Hide the axis\n",
        "#     plt.show()\n",
        "\n",
        "#     return image\n",
        "\n",
        "# def load_handwritten_digits(data_dir):\n",
        "#     data = []\n",
        "#     labels = []\n",
        "\n",
        "#     all_files = []\n",
        "#     for digit in range(10):\n",
        "#         digit_dir = os.path.join(os.path.join(data_dir, str(digit)), str(digit))\n",
        "#         digit_files = [os.path.join(digit_dir, f) for f in os.listdir(digit_dir) if f.endswith('.png')]\n",
        "#         all_files.extend([(f, digit) for f in digit_files])\n",
        "\n",
        "#     random.shuffle(all_files)\n",
        "\n",
        "#     for file_path, digit in all_files:\n",
        "#         try:\n",
        "#             # Open the image\n",
        "#             img = Image.open(file_path)\n",
        "#             # print(f\"Loaded image: {file_path}, mode: {img.mode}, size: {img.size}\")\n",
        "\n",
        "#             # Convert image to RGBA if it's not already\n",
        "#             # if img.mode != 'RGBA':\n",
        "#             #     print(img.mode)\n",
        "#             #     return\n",
        "#             #     img = img.convert('RGBA')\n",
        "\n",
        "#             # Split the image into its separate channels\n",
        "#             # r, g, b, a = img.split()\n",
        "\n",
        "#             # Invert the RGB channels\n",
        "#             # r = r.point(lambda p: 255 - p)\n",
        "#             # g = g.point(lambda p: 255 - p)\n",
        "#             # b = b.point(lambda p: 255 - p)\n",
        "\n",
        "#             # Merge the channels back, keeping the alpha channel unchanged\n",
        "#             # inverted_img = Image.merge(\"RGBA\", (r, g, b, a))\n",
        "\n",
        "#             # Create a black background image\n",
        "#             black_bg = Image.new(\"RGBA\", img.size, (255, 255, 255, 255))\n",
        "\n",
        "#             # Paste the inverted image onto the black background using the alpha channel as mask\n",
        "#             # black_bg.paste(inverted_img, (0, 0), inverted_img)\n",
        "#             black_bg.paste(img, (0, 0), img)\n",
        "\n",
        "#             # Convert to grayscale\n",
        "#             new_img = black_bg.convert('L')\n",
        "#             img_data = np.array(new_img).astype(np.float32)\n",
        "#             # test_img_data = np.array(img.convert('L')).astype(np.float32) / 255.0\n",
        "\n",
        "#             # Debugging step: Print min and max values to check normalization\n",
        "#             # print(f\"Converted Image: {file_path}, min: {img_data.min()}, max: {img_data.max()}\")\n",
        "\n",
        "#             # Display the image to debug if necessary\n",
        "#             # array_to_image(img_data * 255)  # Convert back to 0-255 for display\n",
        "#             # array_to_image(test_img_data * 255)\n",
        "#             # return\n",
        "\n",
        "\n",
        "#             data.append(img_data.flatten())\n",
        "#             labels.append(str(digit))\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error loading file: {file_path}\")\n",
        "#             print(e)\n",
        "\n",
        "#     data = np.array(data)\n",
        "#     labels = np.array(labels)\n",
        "\n",
        "#     return data, labels\n",
        "\n",
        "\n",
        "# # Load images and labels\n",
        "# base_folder = 'dataset'\n",
        "# X, Y = load_handwritten_digits(base_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjgPYZpG4cOd",
        "outputId": "c46fe848-ec98-4c0b-f1c1-ecbe6aadd827"
      },
      "outputs": [],
      "source": [
        "# print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yILIDMwSei66",
        "outputId": "2e945d7c-1d6f-41cc-a620-0618070a0c64"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# X = X / 255 - 0.5\n",
        "\n",
        "# Y_new = DLModel.to_one_hot(10,Y)\n",
        "# print(Y_new.shape)\n",
        "\n",
        "# m = 64638\n",
        "# m_test = X.shape[0] - m\n",
        "# X_train, X_test = X[:m].T, X[m:].T\n",
        "# Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
        "\n",
        "# print(X_train.shape, Y_train.shape)\n",
        "# print(X_test.shape, Y_test.shape)\n",
        "\n",
        "\n",
        "# # np.random.seed(111)\n",
        "# # shuffle_index = np.random.permutation(m)\n",
        "# # X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybKci9IEIBgY",
        "outputId": "5d5794b0-8c95-4e9e-f1d7-a5fb79c50129"
      },
      "outputs": [],
      "source": [
        "# print(X.shape)\n",
        "# print(Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmhUoNmIIBQz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "frjFRkq8tJeV",
        "outputId": "c5d24413-9278-445c-a9e2-b01f41e0f608"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "Hidden = DLNeuronsLayer(\"Hidden\",64,28*28,\"sigmoid\",0.1,'adaptive')\n",
        "Output = DLNeuronsLayer(\"Output\",10,64,\"softmax\",0.1,'adaptive')\n",
        "\n",
        "digit_network = DLNetwork(\"digit_net\")\n",
        "digit_network.add_layer(Hidden)\n",
        "digit_network.add_layer(Output)\n",
        "\n",
        "digit_model = DLModel(\"model\",digit_network,'categorical_cross_entropy')\n",
        "# costs = digit_model.train(X_train, Y_train, 200)\n",
        "# u10.print_costs(costs,200)\n",
        "# digit_network.save_parameters(\"parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l95DyoYmATPV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TrQBeo4Y_8FZ"
      },
      "outputs": [],
      "source": [
        "# digit_network.save_parameters(\"parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbf5FkT91xxW",
        "outputId": "5e84549e-291e-4d3e-8331-74d8a06be5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m digit_network\u001b[38;5;241m.\u001b[39mrestore_parameters(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m digit_model\u001b[38;5;241m.\u001b[39mconfusion_matrix(\u001b[43mX_train\u001b[49m, Y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m digit_model\u001b[38;5;241m.\u001b[39mconfusion_matrix(X_test, Y_test)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "digit_network.restore_parameters(\"parameters\")\n",
        "print(\"Train:\")\n",
        "# digit_model.confusion_matrix(X_train, Y_train)\n",
        "print(\"Test:\")\n",
        "# digit_model.confusion_matrix(X_test, Y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_VZd_GAYnB",
        "outputId": "1d4b0ac4-76c7-4834-d6c0-e30f44c95332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted digit in dataset/5/5/1.png is: 5\n",
            "The predicted digit in dataset/5/5/10.png is: 5\n",
            "The predicted digit in dataset/5/5/100.png is: 5\n",
            "The predicted digit in dataset/5/5/1000.png is: 5\n",
            "The predicted digit in dataset/5/5/10000.png is: 5\n",
            "The predicted digit in dataset/6/6/1.png is: 6\n",
            "The predicted digit in dataset/6/6/10.png is: 6\n",
            "The predicted digit in dataset/6/6/100.png is: 6\n",
            "The predicted digit in dataset/6/6/1000.png is: 6\n",
            "The predicted digit in dataset/6/6/10000.png is: 6\n",
            "The predicted digit in dataset/7/7/1.png is: 7\n",
            "The predicted digit in dataset/7/7/10.png is: 7\n",
            "The predicted digit in dataset/7/7/100.png is: 7\n",
            "The predicted digit in dataset/7/7/1000.png is: 7\n",
            "The predicted digit in dataset/7/7/10000.png is: 7\n",
            "The predicted digit in dataset/8/8/1.png is: 8\n",
            "The predicted digit in dataset/8/8/10.png is: 8\n",
            "The predicted digit in dataset/8/8/100.png is: 8\n",
            "The predicted digit in dataset/8/8/1000.png is: 8\n",
            "The predicted digit in dataset/8/8/10000.png is: 8\n",
            "The predicted digit in dataset/9/9/1.png is: 9\n",
            "The predicted digit in dataset/9/9/10.png is: 9\n",
            "The predicted digit in dataset/9/9/100.png is: 9\n",
            "The predicted digit in dataset/9/9/1000.png is: 9\n",
            "The predicted digit in dataset/9/9/10000.png is: 9\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def evaluateImage(imagePath):\n",
        "    img = Image.open(imagePath)\n",
        "    \n",
        "     \n",
        "    # Create a black background image\n",
        "    if img.mode != 'RGBA':\n",
        "      img = img.convert('RGBA')\n",
        "      print(img.size)\n",
        "\n",
        "    if \"my_digits\" in imagePath:\n",
        "\n",
        "      print(\"here\")\n",
        "\n",
        "    white_bg = Image.new(\"RGBA\", img.size, (255, 255, 255, 255))\n",
        "\n",
        "    # Paste the inverted image onto the black background using the alpha channel as mask\n",
        "    # black_bg.paste(inverted_img, (0, 0), inverted_img)\n",
        "    white_bg.paste(img, (0, 0), img)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    new_img = white_bg.convert('L')\n",
        "    img_data = np.array(new_img).astype(np.float32) / 255 - 0.5\n",
        "\n",
        "    img_data = img_data.reshape(784, 1)\n",
        "\n",
        "\n",
        "    # Forward propagation\n",
        "    Y_hat = digit_model.forward_propagation(img_data)\n",
        "\n",
        "    # Get the predicted digit\n",
        "    predicted_digit = np.argmax(Y_hat)\n",
        "\n",
        "    print(f\"The predicted digit in {imagePath} is: {predicted_digit}\")\n",
        "\n",
        "\n",
        "dataset_path = \"dataset/\"\n",
        "\n",
        "for j in range(5,10):\n",
        "  for i in range(5):\n",
        "    num = 1 * (10 ** i)\n",
        "    evaluateImage(dataset_path + str(j) + \"/\" + str(j) + \"/\" + str(num) + \".png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here\n",
            "The predicted digit in my_digits/1.png is: 1\n",
            "here\n",
            "The predicted digit in my_digits/2.png is: 2\n"
          ]
        }
      ],
      "source": [
        "# my_digits_path = \"my_digits/\"\n",
        "evaluateImage(\"my_digits/1.png\")\n",
        "evaluateImage(\"my_digits/2.png\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
